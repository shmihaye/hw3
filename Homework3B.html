
    <!DOCTYPE html>
    <html lang="en">
        <head>
            <title>Homework3B</title>
            <meta charset="utf-8">
            <style>
                body {
                    margin: 0px;
                    overflow: hidden;
                }
            </style>
        </head>
    <body>

    <div id="container"></div>

    <script src="js/three.js"></script>
    <script id="vertexShader" type="x-shader/x-vertex">
	uniform mat4 modelViewMatrix;
    uniform mat4 projectionMatrix;

	attribute vec3 position;
	
    void main() {
 		gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
	}

    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
        
        /**
        
        
        
        Base code from "Ray Marching: Part 2" by jlfwong: https://www.shadertoy.com/view/lt33z7
        
        
        
        **/
        
        
        
		precision mediump float;
        
        uniform vec2 res;
        uniform float time;
		
        const int MAX_MARCHING_STEPS = 255;
        const float MIN_DIST = 0.0;
        const float MAX_DIST = 100.0;
        const float EPSILON = 0.0001;
        
        /**
         * Constructive solid geometry intersection operation on SDF-calculated distances.
         */
        float intersectSDF(float distA, float distB) {
            return max(distA, distB);
        }

        /**
         * Constructive solid geometry union operation on SDF-calculated distances.
         */
        float unionSDF(float distA, float distB) {
            return min(distA, distB);
        }

        /**
         * Constructive solid geometry difference operation on SDF-calculated distances.
         */
        float differenceSDF(float distA, float distB) {
            return max(distA, -distB);
        }
        
        /**
         * Rotation matrix around the X axis.
         */
        mat3 rotateX(float theta) {
            float c = cos(theta);
            float s = sin(theta);
            return mat3(
                vec3(1, 0, 0),
                vec3(0, c, -s),
                vec3(0, s, c)
            );
        }

        /**
         * Rotation matrix around the Y axis.
         */
        mat3 rotateY(float theta) {
            float c = cos(theta);
            float s = sin(theta);
            return mat3(
                vec3(c, 0, s),
                vec3(0, 1, 0),
                vec3(-s, 0, c)
            );
        }

        /**
         * Rotation matrix around the Z axis.
         */
        mat3 rotateZ(float theta) {
            float c = cos(theta);
            float s = sin(theta);
            return mat3(
                vec3(c, -s, 0),
                vec3(s, c, 0),
                vec3(0, 0, 1)
            );
        }
        
        /**
         * Signed distance function for a cube centered at the origin
         * with width = height = length = 2.0
         */
        float cubeSDF(vec3 p) {
            // If d.x < 0, then -1 < p.x < 1, and same logic applies to p.y, p.z
            // So if all components of d are negative, then p is inside the unit cube
            vec3 d = abs(p) - vec3(1.0, 1.0, 1.0);
            
            // Assuming p is inside the cube, how far is it from the surface?
            // Result will be negative or zero.
            float insideDistance = min(max(d.x, max(d.y, d.z)), 0.0);
            
            // Assuming p is outside the cube, how far is it from the surface?
            // Result will be positive or zero.
            float outsideDistance = length(max(d, 0.0));
            
            return insideDistance + outsideDistance;
        }
        
        /**
         * Signed distance function for a sphere centered at the origin with radius 1.0;
         */
        float sphereSDF(vec3 samplePoint) {
            return length(samplePoint) - 1.0;
        }
        
        float torusSDF( vec3 p, vec2 t )
        {
          vec2 q = vec2(length(p.xz)-t.x,p.y);
          return length(q)-t.y;
        }
        
        /**
         * Signed distance function for an XY aligned cylinder centered at the origin with
         * height h and radius r.
         */
        float cylinderSDF(vec3 p, float h, float r) {
            // How far inside or outside the cylinder the point is, radially
            float inOutRadius = length(p.xy) - r;
            
            // How far inside or outside the cylinder is, axially aligned with the cylinder
            float inOutHeight = abs(p.z) - h/2.0;
            
            // Assuming p is inside the cylinder, how far is it from the surface?
            // Result will be negative or zero.
            float insideDistance = min(max(inOutRadius, inOutHeight), 0.0);

            // Assuming p is outside the cylinder, how far is it from the surface?
            // Result will be positive or zero.
            float outsideDistance = length(max(vec2(inOutRadius, inOutHeight), 0.0));
            
            return insideDistance + outsideDistance;
        }

        /**
         * Signed distance function describing the scene.
         * 
         * Absolute value of the return value indicates the distance to the surface.
         * Sign indicates whether the point is inside or outside the surface,
         * negative indicating inside.
         */
        float sceneSDF(vec3 samplePoint) {
            float cylinder1 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * samplePoint,2.0,0.1);
            float cylinder2 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * rotateY(radians(45.0)) * samplePoint,2.0,0.1);
            float cylinder3 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * rotateY(radians(90.0)) * samplePoint,2.0,0.1);
            float cylinder4 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * rotateY(radians(135.0)) * samplePoint,2.0,0.1);
            float cylinder5 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * rotateY(radians(180.0)) * samplePoint,2.0,0.1);
            float cylinder6 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * rotateY(radians(225.0)) * samplePoint,2.0,0.1);
            float cylinder7 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * rotateY(radians(270.0)) * samplePoint,2.0,0.1);
            float cylinder8 = cylinderSDF(rotateX(radians(45.0 + sin(time) * 45.0)) * rotateY(radians(315.0)) * samplePoint,2.0,0.1);
            float cylinders1and2 = unionSDF(cylinder1,cylinder2);
            float cylinders3and4 = unionSDF(cylinder3,cylinder4);
            float cylinders5and6 = unionSDF(cylinder5,cylinder6);
            float cylinders7and8 = unionSDF(cylinder7,cylinder8);
            float cylinders1thru4 = unionSDF(cylinders1and2,cylinders3and4);
            float cylinders5thru8 = unionSDF(cylinders5and6,cylinders7and8);
            float cylindersObject = unionSDF(cylinders1thru4,cylinders5thru8);
            
            float sphereDist = sphereSDF(samplePoint * 1.5)* cos(time) * 0.005;
           return intersectSDF(sphereDist, cylindersObject);
        }

        /**
         * Return the shortest distance from the eyepoint to the scene surface along
         * the marching direction. If no part of the surface is found between start and end,
         * return end.
         * 
         * eye: the eye point, acting as the origin of the ray
         * marchingDirection: the normalized direction to march in
         * start: the starting distance away from the eye
         * end: the max distance away from the ey to march before giving up
         */
        float shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end) {
            float depth = start;
            for (int i = 0; i < MAX_MARCHING_STEPS; i++) {
                float dist = sceneSDF(eye + depth * marchingDirection);
                if (dist < EPSILON) {
                    return depth;
                }
                depth += dist;
                if (depth >= end) {
                    return end;
                }
            }
            return end;
        }
        
        /**
         * Return the normalized direction to march in from the eye point for a single pixel.
         * 
         * fieldOfView: vertical field of view in degrees
         * size: resolution of the output image
         * fragCoord: the x,y coordinate of the pixel in the output image
         */
        vec3 rayDirection(float fieldOfView, vec2 size, vec2 fragCoord) {
            vec2 xy = fragCoord - size / 2.0;
            float z = size.y / tan(radians(fieldOfView) / 2.0);
            return normalize(vec3(xy, -z));
        }
        
        /**
         * Using the gradient of the SDF, estimate the normal on the surface at point p.
         */
        vec3 estimateNormal(vec3 p) {
            return normalize(vec3(
                sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),
                sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),
                sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))
            ));
        }
        
        /**
         * Lighting contribution of a single point light source via Phong illumination.
         * 
         * The vec3 returned is the RGB color of the light's contribution.
         *
         * k_a: Ambient color
         * k_d: Diffuse color
         * k_s: Specular color
         * alpha: Shininess coefficient
         * p: position of point being lit
         * eye: the position of the camera
         * lightPos: the position of the light
         * lightIntensity: color/intensity of the light
         *
         * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description
         */
        vec3 phongContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye,
                                  vec3 lightPos, vec3 lightIntensity) {
            vec3 N = estimateNormal(p);
            vec3 L = normalize(lightPos - p);
            vec3 V = normalize(eye - p);
            vec3 R = normalize(reflect(-L, N));
            
            float dotLN = dot(L, N);
            float dotRV = dot(R, V);
            
            if (dotLN < 0.0) {
                // Light not visible from this point on the surface
                return vec3(0.0, 0.0, 0.0);
            } 
            
            if (dotRV < 0.0) {
                // Light reflection in opposite direction as viewer, apply only diffuse
                // component
                return lightIntensity * (k_d * dotLN);
            }
            return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));
        }

        /**
         * Lighting via Phong illumination.
         * 
         * The vec3 returned is the RGB color of that point after lighting is applied.
         * k_a: Ambient color
         * k_d: Diffuse color
         * k_s: Specular color
         * alpha: Shininess coefficient
         * p: position of point being lit
         * eye: the position of the camera
         *
         * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description
         */
        vec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye) {
            const vec3 ambientLight = 0.1 * vec3(1.0, 1.0, 1.0);
            vec3 color = ambientLight * k_a;
            
            vec3 light1Pos = vec3(4.0 * sin(time),
                                  2.0,
                                  4.0 * cos(time));
            vec3 light1Intensity = vec3(0.8, 0.8, 0.8);
            
            color += phongContribForLight(k_d, k_s, alpha, p, eye,
                                          light1Pos,
                                          light1Intensity);
            
            vec3 light2Pos = vec3(2.0 * sin(0.37 * time),
                                  2.0 * cos(0.37 * time),
                                  2.0);
            vec3 light2Intensity = vec3(0.8, 0.8, 0.8);
            
            color += phongContribForLight(k_d, k_s, alpha, p, eye,
                                          light2Pos,
                                          light2Intensity);    
            return color;
        }
        
        /**
         * Return a transform matrix that will transform a ray from view space
         * to world coordinates, given the eye point, the camera target, and an up vector.
         *
         * This assumes that the center of the camera is aligned with the negative z axis in
         * view space when calculating the ray marching direction. See rayDirection.
         */
        mat4 viewMatrix(vec3 eye, vec3 center, vec3 up) {
            // Based on gluLookAt man page
            vec3 f = normalize(center - eye);
            vec3 s = normalize(cross(f, up));
            vec3 u = cross(s, f);
            return mat4(
                vec4(s, 0.0),
                vec4(u, 0.0),
                vec4(-f, 0.0),
                vec4(0.0, 0.0, 0.0, 1)
            );
        }
        
		void main()
        {
            vec3 viewDir = rayDirection(45.0, res.xy, gl_FragCoord.xy);
            vec3 eye = vec3(8.0 + cos(time) * 3.0, 7.0 + sin(time) * 3.0, 7.0);
            
            mat4 viewToWorld = viewMatrix(eye, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0));
            
            vec3 worldDir = (viewToWorld * vec4(viewDir, 0.0)).xyz;
            
            float dist = shortestDistanceToSurface(eye, worldDir, MIN_DIST, MAX_DIST);
            
            if (dist > MAX_DIST - EPSILON) {
                // Didn't hit anything
                gl_FragColor = vec4(0.0, 0.0, 0.0, 0.0);
                return;
            }
            
            // The closest point on the surface to the eyepoint along the view ray
            vec3 p = eye + dist * worldDir;
            
            vec3 K_a = vec3(0.2, 0.2, 0.2);
            vec3 K_d = vec3(0.5+cos(time*3.0), 0.5+sin(time * 3.0), 0.2);
            vec3 K_s = vec3(1.0, 1.0, 1.0);
            float shininess = 10.0;
            
            vec3 color = phongIllumination(K_a, K_d, K_s, shininess, p, eye);
            
            gl_FragColor = vec4(color, 1.0);
        }
	</script>

	<script>
		

    var scene;
    var camera;
    var renderer;
    var time = 0.0;

    var plane;
    var planeMaterial;
    var fullScreenQuad;

    //This is the basic scene setup
    scene = new THREE.Scene();
    var width = window.innerWidth;
    var height = window.innerHeight;
    var res = new THREE.Vector2(width,height);

    //orthographic camera can be used for 2D
    camera = new THREE.OrthographicCamera( width / -2, width / 2, height / 2, height / -2, 0.1, 1000 );
    camera.position.z = 0.2;
        
    //we can use a Three.js Plane Geometry along with the orthographic camera to create a "full screen quad"
    plane = new THREE.PlaneBufferGeometry( window.innerWidth, window.innerHeight )
    planeMaterial = new THREE.RawShaderMaterial( {
        uniforms: {
            res: { type: "v2", value: res },
            time: { type: "f", value: time },
        },
        vertexShader: document.getElementById( 'vertexShader' ).innerHTML,
        fragmentShader: document.getElementById( 'fragmentShader' ).innerHTML
    } );
    fullScreenQuad = new THREE.Mesh( plane, planeMaterial );
    scene.add(fullScreenQuad);

    renderer = new THREE.WebGLRenderer();
    renderer.setSize( window.innerWidth, window.innerHeight );
    document.body.appendChild( renderer.domElement );

    render();

    function render() {

        requestAnimationFrame( render );
        
        planeMaterial.uniforms.time.value = performance.now()/1000;
        
        //Then draw the full sceen quad to the on screen buffer, ie, the display
        renderer.render( scene, camera );
        
    }
    </script>
    </body>
    </html>

